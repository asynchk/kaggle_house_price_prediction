{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc_section\"></a>\n",
    "## Table of Contents\n",
    "* [Extract] (#extract)\n",
    "* [Introduction](#top_section)\n",
    "    - [Well... What do we have here?](#section1)\n",
    "* [Exploring the Data](#section2)\n",
    "    - [Categorical Features](#section3)\n",
    "    - [Numerical Features](#section4)\n",
    "    - [Missing Values](#section5)    \n",
    "* [Building the Feature Engineering Machine](#section6)\n",
    "* [Double Check](#section24)\n",
    "    - [Correlation Matrix](#section25)\n",
    "* [Modelling](#section26)\n",
    "    - [Model Selection](#section27)\n",
    "    - [Cross-Validate Models](#section28)\n",
    "    - [Model Results](#section29)\n",
    "    - [ROC'S of the Models](#section30)\n",
    "    - [Learning Curves of the Models](#section31)\n",
    "* [Feature Selection](#section31.1)\n",
    "    - [Feature Importances](#section32)\n",
    "    - [Decision Trees](#section33)    \n",
    "    - [Feature Selection by Recursive Feature Elimination](#section34)\n",
    "    - [Dimension Reduction by Principal Component Analysis](#section35)\n",
    "    - [Reduced Dimension Model Results with Cross-Validation](#sectioncv)\n",
    "* [Plotting Decision Boundaries](#section36)\n",
    "* [Plotting Decision Regions](#section37)\n",
    "* [Submission & Some Last Words](#sectionlst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Extract\"></a>\n",
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top_section\"></a>\n",
    "# 2. Introduction\n",
    "\n",
    "\n",
    "\n",
    "### My main objectives on this project are:\n",
    "\n",
    "* Explorating and visualising the data, trying to get some insights about our dataset\n",
    "* Getting data in better shape by feature engineering to help us in building better models\n",
    "* Building and tuning couple regression models to get some stable results on predicting Titanic disaster outcome\n",
    "\n",
    "### In this notebook we are going to try explore the data we have and going try answer questions like:\n",
    "\n",
    "- What is the ditribution of Sale Price in the training data\n",
    "- What are the categorical and continuous attributes of the data set?\n",
    "- Which attributes are too focused on one attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "# 3. Loading and Exploring the data\n",
    "\n",
    "\n",
    "### [Back To Table of Contents](#toc_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Loading Required Libraries and Shared Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing neccesary packages.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from scipy import interp, stats\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import warnings\n",
    "\n",
    "def plot_category(y_field, x_field:str=\"SalePrice\"):\n",
    "    sns.set(style=\"ticks\", color_codes=True)\n",
    "    g = sns.catplot(x=x_field, y=y_field, data=train_data);\n",
    "    for ax in g.axes.flat:\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_rotation(45)\n",
    "\n",
    "\n",
    "def get_color(existing_color=[])->str:\n",
    "    r = lambda: random.randint(0,255)\n",
    "    _color = '#%02X%02X%02X' % (r(),r(),r())\n",
    "    _ = get_color(existing_color) if _color in existing_color else _color\n",
    "    existing_color.append(_)\n",
    "    return _\n",
    "\n",
    "def plot_with_category(x_field:str, y_field:str='SalePrice'):\n",
    "    y = train_data[y_field]\n",
    "    x = pd.get_dummies(train_data[x_field])\n",
    "    category = list(set(x.columns))\n",
    "#     print(category, data_fields[x_field][\"components\"])\n",
    "    chosen_color = []\n",
    "\n",
    "    for c in category:\n",
    "        # Plot outputs\n",
    "        plt.scatter(x[c], y,  color=get_color(chosen_color))\n",
    "        plt.title(label=f'{y_field} with respect to {data_fields[x_field][\"components\"][c.upper()]}')\n",
    "#         plt.title(label=f'{y_field} with respect to {c}')\n",
    "        # plt.plot(x, y, color='blue', linewidth=3)\n",
    "        plt.show()\n",
    "\n",
    "def pure_plot(x_field:str, y_field:str='SalePrice'):\n",
    "    # Plot outputs\n",
    "    plt.scatter(train_data[x_field], train_data[y_field],  color=get_color())\n",
    "#     plt.plot(x, y, color='blue', linewidth=3)\n",
    "    plt.show()\n",
    "    \n",
    "import time\n",
    "def plot(x_field:str, y_field:str='SalePrice'):\n",
    "#     print(f'Field: {x_field}\\nDescription: {data_fields[x_field][\"description\"]}')\n",
    "#     print('Components\\n', *list(f'- {i}: {j}\\n' for i,j in data_fields[x_field]['components'].items()))\n",
    "    plot_category(x_field=y_field, y_field=x_field) if is_string_dtype(train_data[x_field]) else pure_plot(x_field, y_field)\n",
    "\n",
    "def plot_dist_and_saleprice(attr,figsize=(10, 5),  **kwargs):\n",
    "    f, (ax1, ax2,) = plt.subplots(1, 2, figsize=figsize, **kwargs)\n",
    "    value_counts = all_data[attr].value_counts()\n",
    "    sns.barplot(x=value_counts.index, y=value_counts, hue_order=value_counts.index, ax=ax1)\n",
    "    sale_price = all_data.groupby(attr).SalePrice.median()\n",
    "    sale_price = sale_price[value_counts.index]\n",
    "    sns.barplot(x=sale_price.index, y=sale_price, ax=ax2)\n",
    "    return (ax1, ax2)\n",
    "    \n",
    "def plot_heap_map_corr(data:pd.DataFrame, save:bool=True):\n",
    "\n",
    "    # import matplotlib.pyplot as plt\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Generate a large random dataset\n",
    "    rs = np.random.RandomState(33)\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = data.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    # Set up the matplotlib figure <- for adjust the size\n",
    "    f, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    h_map = sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1,vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax,annot=True)\n",
    "    if save:\n",
    "        h_map.figure.savefig(\"correlation.png\")\n",
    "        \n",
    "        \n",
    "warnings.filterwarnings('ignore') # Disabling warnimgs for clearer outputs\n",
    "pd.options.display.max_columns = 100 # Pandas option to increase max number of columns to display\n",
    "pd.options.display.max_rows = 100\n",
    "plt.style.use('ggplot') # Setting default plot style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train and test data from csv files for visualization\n",
    "\n",
    "train_data = pd.read_csv('./house-prices-advanced-regression-techniques/train.csv')\n",
    "test_data = pd.read_csv('./house-prices-advanced-regression-techniques/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data size and structure\n",
    "\n",
    "Ok we have two sets(train and test) data and in total 2219 observations 80 features. Our target is SalePrice column which is not present on the test set(duh!)... \n",
    "\n",
    "For the rest we gonna inspect them individually soon but  generally speaking they look mostly categorical data with some continuous values like YearBuilt and Fireplaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking train and test sets\n",
    "display(train_data.sample(3))\n",
    "display(test_data.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Eploring Important Attritubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 The response variables; SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = train_data['SalePrice'].value_counts(ascending=True)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "sns.distplot(train_data['SalePrice'], ax=ax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( train_data['SalePrice'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get a general idea on the distribution of our targeted output.\n",
    "\n",
    "As show on the statistics, the avearage distribution lie on around 160,000. The lower and upper quartile is at 130,000 and 214,000 respectively.\n",
    "\n",
    " (c&p)This was expected as few people can afford very expensive houses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging visualization datasets.\n",
    "\n",
    "def basic_data_set_info(train_data, test_data):\n",
    "    num_train_data = train_data.shape[0]\n",
    "    num_test_data = test_data.shape[0]\n",
    "    print(f'Total record is {num_train_data+num_test_data}')\n",
    "    print(f'Training set is {num_train_data}')\n",
    "    print(f'Testing set is {num_test_data}')\n",
    "    all_data = train_data.append(test_data,sort=False, ignore_index=True)\n",
    "    print(f'Number of duplication (by id) is {all_data.shape[0] - len(set(all_data.Id))}')\n",
    "    print(f'Number of features (except target prediction value): {all_data.shape[1]-1}')\n",
    "    # \n",
    "    features = list(all_data.columns)\n",
    "    features.remove('Id')\n",
    "    features.remove('SalePrice')\n",
    "    missing = (all_data[features].isnull().sum()/all_data[features].isnull().count()).sort_values(ascending=False)\n",
    "    missing = pd.DataFrame({'Missing – NA(%)':round(missing[missing>0]*100,2)})\n",
    "    print(missing.head(n=100))\n",
    "    print(f'\\n{missing.shape[0]} features have missing data')\n",
    "#     missing_quant = (all_data[quantity].isnull().sum()/data_all[quantity].isnull().count()).sort_values(ascending=False)\n",
    "#     missing_quant = missing_quant[missing_quant > 0] * 100\n",
    "#     print(\"There are {} quantitative features with  missing values :\".format(missing_quant.shape[0]))\n",
    "#     missing_quant = pd.DataFrame({'Percent' :missing_quant})\n",
    "#     missing_quant.head()\n",
    "    return all_data.copy()\n",
    "\n",
    "all_data = basic_data_set_info(train_data, test_data)\n",
    "display(all_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# Numeric Attritubes\n",
    "\n",
    "We get a first glimpse to the correlation of all numeric attritubes with SalePrice the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_vars = train_data.apply()\n",
    "# display(train_data.d_type)\n",
    "\n",
    "numeric_vars = train_data.select_dtypes(include=['int64', 'float64'])\n",
    "# numeric_vars = pd.concat([numeric_vars['SalePrice'], numeric_vars[:-1]])\n",
    "# numeric_attritubes = numeric_vars.columns.values\n",
    "numeric_attritubes = list(numeric_vars)\n",
    "numeric_attritubes.insert(0, numeric_attritubes.pop(numeric_attritubes.index('SalePrice')))\n",
    "\n",
    "# reorder column SalePrice to the front\n",
    "numeric_vars = numeric_vars[numeric_attritubes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = numeric_vars.corr()\n",
    "# display(corr)\n",
    "corr = corr.loc[corr['SalePrice']>0.5, corr['SalePrice']>0.5]\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmin=0.3, vmax=1, center=0.6, annot=True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the numeric values, ony 10 numeric attributes has a corrleation higher than 0.5 with the saleprice\n",
    "\n",
    "As seen from the first column, OverallQual has the highest correlation with the SalePrice. The second is GrLiveArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is 2919 entries in total with 80 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking merged shape\n",
    "display(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "## Categorical Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting categorical data for univariate analysis\n",
    "cats = ['MSSubClass', 'MSZoning', 'Street', 'Alley',\n",
    "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
    "       'OverallQual', 'OverallCond', 'RoofStyle',\n",
    "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
    "        'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "        'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType',\n",
    "        'SaleCondition'\n",
    "       ]\n",
    "\n",
    "\n",
    "def plotFrequency(cats):\n",
    "    #\"A plot for visualize categorical data, showing both absolute and relative frequencies\"\n",
    "    fig, axes = plt.subplots(math.ceil(len(cats) / 2), 2, figsize=(20,12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, cat in zip(axes, cats):\n",
    "        if cat == 'Survived':\n",
    "            total = float(len(train_data[cat]))\n",
    "        else:\n",
    "            total = float(len(all_data[cat]))\n",
    "        sns.countplot(all_data[cat], palette='plasma', ax=ax)\n",
    "\n",
    "        for p in ax.patches:\n",
    "            height = p.get_height()\n",
    "            ax.text(p.get_x() + p.get_width() / 2.,\n",
    "                    height + 10,\n",
    "                    '{:1.2f}%'.format((height / total) * 100),\n",
    "                    ha=\"center\")\n",
    "\n",
    "        plt.ylabel('Count', fontsize=15, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFrequency(cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "## 5. Missing Values\n",
    "\n",
    "**Observations:**\n",
    "- PoolQC,MiscFeature,Alley, Fence have the most missing values\n",
    "- NaN values may represent None as a categorical attritubes\n",
    "\n",
    "### [Back To Table of Contents](#toc_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising missing data\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(25, 25))\n",
    "half = len(train_data)/2\n",
    "sns.heatmap(train_data.loc[:half].isnull(),\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            cmap='magma',\n",
    "            ax=ax[0])\n",
    "sns.heatmap(test_data.isnull(),\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            cmap='magma',\n",
    "            ax=ax[1])\n",
    "\n",
    "ax[0].set_title('Train Data Missing Values')\n",
    "ax[1].set_title('Test Data Missing Values')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Table to see NA values and class in total data set\n",
    "\n",
    "def get_na_and_d_type(column):\n",
    "    num_na = column.isnull().sum()\n",
    "    dtype = column.dtype\n",
    "    sample =column.sample(n=4).reset_index( drop=True)\n",
    "    data_1= pd.Series({'number of missing data': num_na,'data type': dtype})\n",
    "    return pd.concat([data_1, sample, ], )\n",
    "\n",
    "all_data_na = all_data.apply(get_na_and_d_type, axis=0)\n",
    "# all_data_na = all_data_na.loc[all_data_na['number of missing data'] != 0]\n",
    "# display(all_data_na) \n",
    "display(all_data_na.T) \n",
    "\n",
    "# all_data_na_sorted = all_data_na.sort_values(by='number of missing data', axis=1, ascending=False)\n",
    "# display(all_data_na_sorted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- PoolQC,MiscFeature,Alley, Fence have the most missing values\n",
    "- NaN values may represent None as a categorical attritubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na_top = all_data.apply(lambda column: column.isnull().sum(), axis=0).sort_values(ascending=False).head(30)\n",
    "all_data_na_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Dealing with Missing data\n",
    "\n",
    "Inputing missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share Functions\n",
    "def convert_to_ordinary(all_data, order_val, field):\n",
    "    print(f'{field} values: {set(all_data[field].values)}')\n",
    "    valmap = {v:i for i,v in enumerate(order_val)}\n",
    "    all_data[field] = all_data[field].replace(valmap)\n",
    "    return all_data[field]\n",
    "\n",
    "def fillna_by_mode(all_data, field:str):\n",
    "    return all_data[field].fillna(all_data[field].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 MSZoning and Other Categorical Values\n",
    "\n",
    "There is four missing data. The values are categorical. There is not other variables in common nature to infer the missing values.\n",
    "\n",
    "\n",
    "Assign mode to the missing value, in condition that: \n",
    "* If the distribution of one group is dominant and\n",
    "* The distribution of different group is comparable\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "    MSZoning\n",
    "       A\tAgriculture\n",
    "       C\tCommercial\n",
    "       FV\tFloating Village Residential\n",
    "       I\tIndustrial\n",
    "       RH\tResidential High Density\n",
    "       RL\tResidential Low Density\n",
    "       RP\tResidential Low Density Park \n",
    "       RM\tResidential Medium Density\n",
    "```       \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data.MSZoning.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dist_and_saleprice('MSZoning')    \n",
    "display(all_data['MSZoning'].value_counts())\n",
    "\n",
    "MSZoning_mode = all_data['MSZoning'].mode()\n",
    "sale_price = all_data.groupby('MSZoning').SalePrice.median()\n",
    "display(sale_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MSZoning'] = fillna_by_mode(all_data, field='MSZoning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1.2 Other Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alley\n",
    "all_data['Alley'] = all_data['Alley'].fillna('NA')\n",
    "plot_dist_and_saleprice('Alley' )\n",
    "\n",
    "\n",
    "#Utilities\n",
    "all_data['Utilities'] = all_data['Utilities'].fillna('AllPub')\n",
    "plot_dist_and_saleprice('Utilities' )\n",
    "\n",
    "# Exterior1st\n",
    "mode_value = pd.concat([all_data['Exterior1st'], all_data['Exterior2nd']]).mode()\n",
    "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(mode_value[0])\n",
    "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(mode_value[0])\n",
    "(ax1, ax2) = plot_dist_and_saleprice('Exterior1st', figsize=(20, 6))\n",
    "ax1.tick_params(labelrotation=45)\n",
    "ax2.tick_params(labelrotation=45)\n",
    "(ax1, ax2) = plot_dist_and_saleprice('Exterior2nd', figsize=(20, 6) )\n",
    "ax1.tick_params(labelrotation=45)\n",
    "ax2.tick_params(labelrotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign the mode of the attributes to the NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.2 LotFrontage and Other Numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "486 NAs. Linear feet of street connected to property\n",
    "\n",
    "We assign the NA to zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f,ax1 = plt.subplots(figsize =(20,10))\n",
    "all_data['LotFrontage'] = all_data['LotFrontage'].fillna(0)\n",
    "display(all_data.loc[all_data['LotFrontage'].isnull()])\n",
    "data = all_data[['LotFrontage', 'SalePrice']]\n",
    "\n",
    "grid = sns.JointGrid(x='LotFrontage',y='SalePrice',data=data, height =8)\n",
    "grid.plot_joint(sns.scatterplot, color=\"g\")\n",
    "grid.plot_marginals(sns.rugplot, height=1, color=\"g\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not a strong relationship with the SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[['LotFrontage', 'SalePrice']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign the NA to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.3 Masonry veneer\n",
    "\n",
    "MasVnrType should be closed related to MasVnrArea\n",
    "\n",
    "MasVnrType has 24 NAs, MasVnrArea has 23 NAs. The two values should coexist to describe both the Masonry veneer type and area.\n",
    "\n",
    "       MasVnrType: Masonry veneer type\n",
    "   \n",
    "       BrkCmn\tBrick Common\n",
    "       BrkFace\tBrick Face\n",
    "       CBlock\tCinder Block\n",
    "       None\tNone\n",
    "       Stone\tStone\n",
    "       \n",
    "       \n",
    "       MasVnrArea: Masonry veneer area in square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_dist_and_saleprice('MasVnrType')\n",
    "masVnrType_data  = all_data[['MasVnrType', 'MasVnrArea','SalePrice']]\n",
    "\n",
    "f, (ax) = plt.subplots(1, 1, figsize=(10, 5))\n",
    "sns.scatterplot(x=\"MasVnrArea\", y=\"SalePrice\", hue=\"MasVnrType\", hue_order=all_data.MasVnrType.value_counts().index,\n",
    "                     data=masVnrType_data, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_data = all_data.loc[all_data.MasVnrType.isnull() & all_data.MasVnrArea.notnull() ]\n",
    "abnormal_data\n",
    "\n",
    "# all_data.loc[all_data.MasVnrType.isnull() & all_data.MasVnrArea.notnull() ].replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abnormal data has MasVnrArea = 198.0 and MasVnrType in Nan. We shall asign MasVnrType as the mode of the dataset except None, i.e. BrkFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: modify the abnormal_data\n",
    "\n",
    "\n",
    "## Fill NA with 'None'\n",
    "all_data['MasVnrType'].fillna('None', inplace=True)\n",
    "all_data['MasVnrArea'].fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.4 Basement Variables\n",
    "\n",
    "There are in total 11 basement related variables. 5 variables with 79 ~ 82 missing values, 6 variables with 1 to 2 missing values.\n",
    "\n",
    "We check if the missing values belong to the same datasets.\n",
    "\n",
    "    BsmtQual: Evaluates the height of the basement\n",
    "\n",
    "       Ex\tExcellent (100+ inches)\t\n",
    "       Gd\tGood (90-99 inches)\n",
    "       TA\tTypical (80-89 inches)\n",
    "       Fa\tFair (70-79 inches)\n",
    "       Po\tPoor (<70 inches\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "    BsmtCond: Evaluates the general condition of the basement\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical - slight dampness allowed\n",
    "       Fa\tFair - dampness or some cracking or settling\n",
    "       Po\tPoor - Severe cracking, settling, or wetness\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "    BsmtExposure: Refers to walkout or garden level walls\n",
    "\n",
    "       Gd\tGood Exposure\n",
    "       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n",
    "       Mn\tMimimum Exposure\n",
    "       No\tNo Exposure\n",
    "       NA\tNo Basement\n",
    "\t\n",
    "    BsmtFinType1: Rating of basement finished area\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\t\t\n",
    "    BsmtFinSF1: Type 1 finished square feet\n",
    "\n",
    "    BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "\n",
    "       GLQ\tGood Living Quarters\n",
    "       ALQ\tAverage Living Quarters\n",
    "       BLQ\tBelow Average Living Quarters\t\n",
    "       Rec\tAverage Rec Room\n",
    "       LwQ\tLow Quality\n",
    "       Unf\tUnfinshed\n",
    "       NA\tNo Basement\n",
    "\n",
    "    BsmtFinSF2: Type 2 finished square feet\n",
    "\n",
    "    BsmtUnfSF: Unfinished square feet of basement area\n",
    "\n",
    "    TotalBsmtSF: Total square feet of basement area\n",
    "    \n",
    "    BsmtFullBath: Basement full bathrooms\n",
    "\n",
    "    BsmtHalfBath: Basement half bathrooms\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_vars = [\n",
    "    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'\n",
    "]\n",
    "\n",
    "display(all_data[basement_vars].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the missing values belong to the same datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_null = all_data[\n",
    "    all_data['BsmtQual'].isnull() &\n",
    "    all_data['BsmtCond'].isnull() &\n",
    "    all_data['BsmtExposure'].isnull() &\n",
    "    all_data['BsmtFinType1'].isnull() &\n",
    "    all_data['BsmtFinType2'].isnull()\n",
    "]\n",
    "\n",
    "display(bsmt_null.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these 79 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assign the 79 to NA\n",
    "\n",
    "basements_na_values_mapping = {\n",
    "    'BsmtQual': 'NA',\n",
    "    'BsmtCond': 'NA',\n",
    "    'BsmtExposure': 'NA',\n",
    "    'BsmtFinType1': 'NA',\n",
    "    'BsmtFinType2': 'NA'\n",
    "}\n",
    "\n",
    "# Fill NAs of the 79 datasets \n",
    "all_data[\n",
    "    all_data['BsmtQual'].isnull() &\n",
    "    all_data['BsmtCond'].isnull() &\n",
    "    all_data['BsmtExposure'].isnull() &\n",
    "    all_data['BsmtFinType1'].isnull() &\n",
    "    all_data['BsmtFinType2'].isnull()\n",
    "] = all_data[\n",
    "    all_data['BsmtQual'].isnull() &\n",
    "    all_data['BsmtCond'].isnull() &\n",
    "    all_data['BsmtExposure'].isnull() &\n",
    "    all_data['BsmtFinType1'].isnull() &\n",
    "    all_data['BsmtFinType2'].isnull()\n",
    "].fillna(value=basements_na_values_mapping\n",
    "       )\n",
    "\n",
    "display(all_data[basement_vars].isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Bsmt = all_data[basement_vars]\n",
    "\n",
    "                        \n",
    "display(data_Bsmt.loc[all_data.BsmtQual.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtCond.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtExposure.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtFinSF1.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtFinSF2.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtFinType2.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtUnfSF.isna()])\n",
    "display(data_Bsmt.loc[all_data.TotalBsmtSF.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtFullBath.isna()])\n",
    "display(data_Bsmt.loc[all_data.BsmtHalfBath.isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* BsmtQual: For data with missing BsmtQual values,  the BsmtFinType are unfinished, Basement Unfinished area are not null and equals to Total BsmtSF, it should be fair to assign the mode of BsmtQaul to the missing values\n",
    "\n",
    "\n",
    "* BsmtFinType2: the data has valid unfinished surface area, so BsmtFinType2 should be 'Unf'\n",
    "Convert BsmtFullBath BsmtHalfBath to 0\n",
    "\n",
    "* BsmtExposure, BsmtFinSF1, , BsmtUnfSF,  TotalBsmtSF, BsmtFullBath, BsmtHalfBath: Fill NA/ 0 for Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.BsmtQual = all_data.BsmtQual.fillna(all_data.BsmtQual.mode()[0])\n",
    "all_data.BsmtCond = all_data.BsmtCond.fillna(all_data.BsmtCond.mode()[0])\n",
    "all_data.BsmtExposure = all_data.BsmtExposure.fillna('NA')\n",
    "all_data.BsmtFinSF1 = all_data.BsmtFinSF1.fillna(0.0)\n",
    "all_data.BsmtFinSF2 = all_data.BsmtFinSF2.fillna(0.0)\n",
    "all_data.BsmtFinType2 = all_data.BsmtFinType2.fillna('Unf')\n",
    "all_data.BsmtUnfSF = all_data.BsmtUnfSF.fillna(0.0)\n",
    "all_data.TotalBsmtSF = all_data.TotalBsmtSF.fillna(0.0)\n",
    "all_data.BsmtFullBath = all_data.BsmtFullBath.fillna(0.0)\n",
    "all_data.BsmtHalfBath = all_data.BsmtHalfBath.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display(all_data.apply(lambda column: column.isnull().sum(), axis=0).sort_values(ascending=False).head(30))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes is ordinal, we can convert them to scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assign the 79 to NA\n",
    "# Ex\tExcellent (100+ inches)\t\n",
    "#        Gd\tGood (90-99 inches)\n",
    "#        TA\tTypical (80-89 inches)\n",
    "#        Fa\tFair (70-79 inches)\n",
    "#        Po\tPoor (<70 inches\n",
    "#        NA\n",
    "\n",
    "\n",
    "#Declare Reusable Ordinal\n",
    "ordinal_5_keys = ['NA', 'No', 'Mn', 'Av', 'Gd']\n",
    "ordinal_6_keys = ['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
    "ordinal_7_keys = ['NA', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ']\n",
    "all_data.BsmtQual = convert_to_ordinary(all_data, ordinal_6_keys, 'BsmtQual')\n",
    "all_data.BsmtCond = convert_to_ordinary(all_data, ordinal_6_keys, 'BsmtCond')\n",
    "all_data.BsmtExposure = convert_to_ordinary(all_data, ordinal_5_keys, 'BsmtExposure')\n",
    "all_data.BsmtFinType1 = convert_to_ordinary(all_data, ordinal_7_keys, 'BsmtFinType1')\n",
    "all_data.BsmtFinType2 = convert_to_ordinary(all_data, ordinal_7_keys, 'BsmtFinType2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) =  plt.subplots(2, 1, figsize=(10, 17))\n",
    "sns.boxplot(x=\"BsmtFinType1\", y=\"SalePrice\",\n",
    "            hue=\"BsmtCond\",\n",
    "            data=all_data,\n",
    "           ax=ax1)\n",
    "sns.boxplot(x=\"BsmtFinType2\", y=\"SalePrice\",\n",
    "            hue=\"BsmtCond\",\n",
    "            data=all_data,\n",
    "            ax=ax2)\n",
    "f, (ax1, ax2) =  plt.subplots(2, 1, figsize=(10, 17))\n",
    "sns.boxplot(x=\"BsmtCond\", y=\"SalePrice\",\n",
    "            hue=\"BsmtFinType1\",\n",
    "            data=all_data,\n",
    "           ax=ax1)\n",
    "sns.boxplot(x=\"BsmtCond\", y=\"SalePrice\",\n",
    "            hue=\"BsmtFinType2\",\n",
    "            data=all_data,\n",
    "            ax=ax2)\n",
    "f, (ax1, ax2) =  plt.subplots(2, 1, figsize=(10, 17))\n",
    "sns.stripplot(x=\"BsmtFinSF1\",  y=\"BsmtFinType1\", hue=\"BsmtFinSF1\", data=all_data,\n",
    "            ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.4 Garage Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# from float type to int type\n",
    "all_data.GarageYrBlt = all_data.GarageYrBlt.astype('Int64')\n",
    "all_data[['GarageYrBlt','YearBuilt']]\n",
    "_ = pd.DataFrame({'diff': all_data['GarageYrBlt']-all_data['YearBuilt']})\n",
    "\n",
    "# print(f'Similarity GarageYrBlt and YearBuilt:{(_[ _[\"diff\"]==0 ].count()/_.shape[0] *100)}%\\n')\n",
    "\n",
    "# Fillna by other field\n",
    "all_data.GarageYrBlt = all_data.GarageYrBlt.fillna(all_data['YearBuilt'])\n",
    "all_data[['GarageYrBlt','YearBuilt']]\n",
    "\n",
    "# all_data[['GarageYrBlt','GarageType', 'GarageFinish', 'GarageCond', 'GarageQual']]\n",
    "\n",
    "# Since the missing rate of Garage* features are very similar, we may check if they have the phenomon -> the garage may not really exist\n",
    "# Filter out one of the null field\n",
    "set_159 = all_data[\n",
    "#     all_data['GarageType'].isnull()\n",
    "    all_data['GarageFinish'].isnull()\n",
    "#     all_data['GarageCond'].isnull()&\n",
    "#     all_data['GarageQual'].isnull()\n",
    "][['Id','GarageYrBlt','GarageType', 'GarageFinish', 'GarageCond', 'GarageQual', 'GarageArea', 'GarageCars']]\n",
    "\n",
    "\n",
    "set_157 = all_data[\n",
    "    all_data['GarageType'].isnull()&\n",
    "    all_data['GarageFinish'].isnull()&\n",
    "    all_data['GarageCond'].isnull()&\n",
    "    all_data['GarageQual'].isnull()\n",
    "][['Id','GarageYrBlt','GarageType', 'GarageFinish', 'GarageCond', 'GarageQual', 'GarageArea', 'GarageCars']]\n",
    "\n",
    "\n",
    "print(f'Bias Id: {set(set_159.Id) - set(set_157.Id)}')\n",
    "\n",
    "# Seems 2127 has carage while 2577 no\n",
    "set_159[(set_159.Id == 2577) | (set_159.Id == 2127) ]\n",
    "\n",
    "# TODO Clean 2577\n",
    "# all_data[all_data.Id==2577].GarageType\n",
    "# Clean 2127\n",
    "# all_data[all_data.Id==2127] = all_data[all_data.Id==2127].fillna(all_data.mode().iloc[0])\n",
    "\n",
    "all_data.GarageCars = all_data.GarageType.fillna(0)\n",
    "all_data.GarageArea = all_data.GarageType.fillna(0)\n",
    "\n",
    "# Fill na to be factor\n",
    "all_data.GarageType = all_data.GarageType.fillna('NoGarage')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the ordinal value\n",
    "all_data.GarageFinish = convert_to_ordinary(all_data, [np.NaN, 'Unf', 'RFn', 'Fin'], 'GarageFinish')\n",
    "all_data.GarageQual = convert_to_ordinary(all_data, [np.NaN, 'Po', 'Fa', 'TA','Gd','Ex'], 'GarageQual')\n",
    "all_data.GarageCond = convert_to_ordinary(all_data, [np.NaN, 'Po', 'Fa', 'TA','Gd','Ex'], 'GarageCond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# encode this variable as the values are ordinal\n",
    "\n",
    "# Check the PoolArea\n",
    "all_data.PoolQC = convert_to_ordinary(all_data, [np.NaN, 'Fa', 'TA','Gd','Ex'], 'PoolQC')\n",
    "\n",
    "# There are 3 records that have PoolArea but do not have PoolQC -> consider to use the linear regression for OverallQual and PoolQC\n",
    "all_data[(all_data.PoolQC==0)& (all_data.PoolArea>0)][['PoolQC', 'PoolArea', 'OverallQual']]\n",
    "# By plotting the chat, we can see the trend PoolQC is matched with OverallQual\n",
    "# plot(y_field='OverallQual', x_field='PoolQC')\n",
    "\n",
    "\n",
    "# Handling MiscFeature, to eliminate the None value for future processing\n",
    "all_data.MiscFeature = all_data.MiscFeature.fillna('None')\n",
    "# x = sns.barplot(x=\"MiscFeature\", y=\"SalePrice\", data=all_data)\n",
    "\n",
    "# Within Fireplace Quality, there are 1420 NAs. Number of fireplaces is complete.\n",
    "print(f'Missing Fireplace is match: {all_data.Fireplaces[all_data.Fireplaces==0].count() == len(all_data.FireplaceQu[all_data.FireplaceQu.isnull()])}')\n",
    "all_data.FireplaceQu = convert_to_ordinary(all_data, [np.NaN, 'Po', 'Fa', 'TA','Gd','Ex'], 'FireplaceQu')\n",
    "\n",
    "\n",
    "all_data['Functional'] = fillna_by_mode(all_data, field='Functional')\n",
    "# all_data.Functional[all_data.Functional.isnull()\n",
    "all_data.Functional = convert_to_ordinary(all_data, ['Sal', 'Sev', 'Maj2','Maj1','Mod','Min2','Min1','Typ'], 'Functional')\n",
    "# plot('Functional')\n",
    "\n",
    "\n",
    "all_data['SaleType'] = fillna_by_mode(all_data, field='SaleType')\n",
    "# plot('SaleType')\n",
    "# plot('SaleType')\n",
    "# `KitchenAbvGr` is no NA nad 1NA in KitchenQual\n",
    "len(all_data.KitchenQual[all_data.KitchenQual.isnull()])\n",
    "all_data['KitchenQual'] = fillna_by_mode(all_data, field='KitchenQual')\n",
    "all_data.KitchenQual = convert_to_ordinary(all_data, ['Po', 'Fa', 'TA','Gd','Ex'], 'KitchenQual')\n",
    "all_data.KitchenAbvGr\n",
    "# set(all_data.columns)\n",
    "# plot(x_field='KitchenAbvGr')\n",
    "# plot('KitchenQual')\n",
    "\n",
    "\n",
    "\n",
    "# Since the NA is no pool -> convert to ordinary\n",
    "all_data.Fence = convert_to_ordinary(all_data, [np.NaN, 'MnWw', 'GdWo','MnPrv','GdPrv'], 'Fence')\n",
    "# plot('Fence')\n",
    "\n",
    "# Electrical ->1 NA, fill by Mode\n",
    "len(all_data.Electrical[all_data.Electrical.isnull()])\n",
    "all_data['Electrical'] = fillna_by_mode(all_data, field='Electrical')\n",
    "# plot('Electrical')\n",
    "\n",
    "# all_data.Fence[all_data.Fence.isnull()]\n",
    "\n",
    "\n",
    "display(all_data.apply(lambda column: column.isnull().sum(), axis=0).sort_values(ascending=False).head(30))\n",
    "train_data_set = all_data[0:1459].copy()\n",
    "train_data_set = train_data_set.drop(['Id'], axis=1)\n",
    "\n",
    "plot_heap_map_corr(train_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 MSSubClass\n",
    "\n",
    "Categorical class is labeled as Number\n",
    "\n",
    "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "        30\t1-STORY 1945 & OLDER\n",
    "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50\t1-1/2 STORY FINISHED ALL AGES\n",
    "        60\t2-STORY 1946 & NEWER\n",
    "        70\t2-STORY 1945 & OLDER\n",
    "        75\t2-1/2 STORY ALL AGES\n",
    "        80\tSPLIT OR MULTI-LEVEL\n",
    "        85\tSPLIT FOYER\n",
    "        90\tDUPLEX - ALL STYLES AND AGES\n",
    "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150\t1-1/2 STORY PUD - ALL AGES\n",
    "       160\t2-STORY PUD - 1946 & NEWER\n",
    "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_name= {\n",
    "    20: '1-STORY 1946 & NEWER ALL STYLES',\n",
    "    30: '1-STORY 1945 & OLDER',\n",
    "    40: '1-STORY W/FINISHED ATTIC ALL AGES',\n",
    "    45:'1-1/2 STORY - UNFINISHED ALL AGES',\n",
    "    50:'1-1/2 STORY FINISHED ALL AGES',\n",
    "    60:'2-STORY 1946 & NEWER',\n",
    "    70:'2-STORY 1945 & OLDER',\n",
    "    75:'2-1/2 STORY ALL AGES',\n",
    "    80:'SPLIT OR MULTI-LEVEL',\n",
    "    85:'SPLIT FOYER',\n",
    "    90:'DUPLEX - ALL STYLES AND AGES',\n",
    "    120:'1-STORY PUD (Planned Unit Development) - 1946 & NEWER',\n",
    "    150:'1-1/2 STORY PUD - ALL AGES',\n",
    "    160:'2-STORY PUD - 1946 & NEWER',\n",
    "    180:'PUD - MULTILEVEL - INCL SPLIT LEV/FOYER',\n",
    "   190: '2 FAMILY CONVERSION - ALL STYLES AND AGES'\n",
    "}\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Get Median and Count Data\n",
    "x = all_data['MSSubClass']\n",
    "data = train_data.groupby('MSSubClass').SalePrice.agg(['median', 'count'])\n",
    "# Rename Index for better information\n",
    "data.rename(index=index_name, inplace=True)\n",
    "\n",
    "sns.barplot(x=data.index, y=data['median'].values, palette=\"rocket\", ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LotArea\n",
    "Check the relationship with LotFrontage,despit the similarity in name, they do not have much relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[['LotArea', 'LotFrontage']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import create_report\n",
    "create_report(all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
